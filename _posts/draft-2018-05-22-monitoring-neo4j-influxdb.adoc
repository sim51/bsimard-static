= Monitoring Neo4j with influxdb TICK stack
Benoit Simard <contact@bsimard.com>
:page-layout: post
:page-locale: en
:page-description: When you push a service in production, it's important to monitor its health status.This rule should be applied for Neo4j, and you will see how to do it with the TICK stack (from influxDB).
:page-image: /public/images/monitor-neo4j-influx/banner.png
:page-tags: sigma, graph, visualisation, dataviz
:page-ref: monitoring-ne04j-influx
:toc:

== Introduction

When you push a service in production, it's important to monitor its health status.
This will allow you to see if everything is OK, to be alerted if something is going wrong but also in a case of a problem, to make some investigations.

This rule should be applied for Neo4j, and you will see how to do it with the TICK stack (from influxDB).

But before to explain how to do it for Neo4j, let talk a little about Influxdb.

== Influxdb

=== Concept

https://www.influxdata.com[Influx DB] is a https://en.wikipedia.org/wiki/Time_series_database[time series database].
It's made to store and query data in times, so it's the perfect tool to store metrics of a system.

Influx has 6 key concepts : time, field, tag, measurement, retention policy and series.

It's better to take an example to understand those concepts.

Imagine that you have a captor of temperature and humidity in your living room and an other one in your bed room.
Each time you will read one, you will receive the data at a point of time.

Because it's the same kind of data, you will store them at the same place.
But you also want to be able to distinguish the data from the living room and the bedroom.

At the end, you will have something like that :

[source]
----
name: captor_temperature_humidity
----------------------------------
time                    tempreature   humidity   room
2015-08-18T00:00:00Z    18.3          51.2       Living Room
2015-08-18T00:00:00Z    16.7          48.9       Bed Room
2015-08-18T00:01:00Z    18.5          51.1       Living Room
2015-08-18T00:01:02Z    16.9          49.0       Bed Room
...
----

Here we have a *measurement name* called `captor_temperature_humidity` (you can think about it like a table in SQL) and each line is *measurement*.
*measurement* is composed of : _time_ , _temperature_, _humidity_ and _room_

*Temperature* and *humidity* are measurement's *fields*, and their values are the data you want to follow in time.
On each measurement, I have added the *room* to know where comes the measurement. It's a measurement's *tag* (a metadata), and you can have mutliple tags for a measurement.

By the time, you will have a very huge number of measurement, and usually you don't want to save them forover.
It's where the concept of *retention policy* takes place.

You can configure the database :

* to delete measurements older than X (X is in seconde, minute, ..., year)
* to aggregate measurements older than X (X is in seconde, minute, ..., year) by minute, day, ..., year

And you can create a chain of retention policy :

* aggregate per minute for data older than a day
* aggregate per hour for data older than a 3 days
* aggregate per day for data older than a week
* delete data older than a years

=== The TICK stack

TICK stack is composed of :

* *Telegraf :* is the agent that will collect the metrics, and write them in an influx database.
* *Influx :* The time series database
* *Chronograf :* A web application that allow you to explore your data and to create dashboard.
* *Kapacitor :* The alerting system of the stack

It's a complete stack to collect, manage and exploit your time series data, so it's perfect for my monitoring purpose.

== The architecture

Generally there is a server where all the metrics are a centralized, and where all the monitoring application are installed.
I will call it the *Monitoring server*.

This server will save all the metrics fron your system, and to do it there is two methods :

* *push* : metrics are directly pushed to the monitoring server by using an agent on each server that you want to monitor.
* *pull* : the monitoring system will query all your servers to collect the metrics.

Generally, the first solution is prefered, and it's the one that I will put in place.

This is the architecture schema :

[graphviz]
----
digraph G {
  rankdir=TB;

  newrank=true
  subgraph cluster_1 {
    node [style=filled];
    color=lightgrey ;
    Neo4j [margin=0.2 shape=none label="Neo4j"];
    Telegraf [margin=0.2 shape=none label="Telegraf"];
    Neo4j -> Telegraf;
  }

  newrank=true
  subgraph cluster_2 {
    node [style=filled];
    color=red;
    Influx [margin=0.2 shape=none label="Influxdb"];
    Chronograf [margin=0.2 shape=none label="Chronograf"];
    Kapacitor [margin=0.2 shape=none label="Kapacitor"];
    Chronograf -> Influx;
    Kapacitor -> Influx;
  }

  Telegraf -> Influx;
  {rank=same Telegraf Influx}
}
----
In red you have the monitoring server, and in grey the monitored server.

NOTE: With this kind of architecture, Neo4j send metrics locally, so it's very fast.
By the way, the Neo4j graphite connector is using TCP, but if it was UDP, it change nothing (and this architecture allows you to use UDP between your server and the agent, because it's local, so there is no lost of data).

== The monitored server

=== Neo4j

In its *Enterprise Edition*, Neo4j has a https://neo4j.com/docs/operations-manual/current/monitoring/metrics/[monitoring system].
In fact there is four ways to monitor it :

* *JMX :* it's a standard java functionnality that allow you to retrive some metrics values.
* *Graphite connector :* you just have to configure your Graphana server, and Neo4j will send its metrics regulary.
* *Prometheus connector :* same as for Graphite but for Prometheus time series database.
* *CSV file :*  Neo4j dumps all its metrics at a regular time interval

*Telegraf* is compatible with the Graphite protocol, so I will use it.

The configuration is really simple, just edit your `neo4j.conf` file and put at the end those lines :

[source,properties]
----
# Setting for enabling all supported metrics.
metrics.enabled=true
# Setting for enabling all Neo4j specific metrics.
metrics.neo4j.enabled=true
# Setting for exposing metrics about transactions; number of transactions started, committed, etc.
metrics.neo4j.tx.enabled=true
# Setting for exposing metrics about the Neo4j page cache; page faults, evictions, flushes and exceptions, etc.
metrics.neo4j.pagecache.enabled=true
# Setting for exposing metrics about approximately entities are in the database; nodes, relationships, properties, etc.
metrics.neo4j.counts.enabled=true
# Setting for exposing metrics about the network usage of the HA cluster component.
metrics.neo4j.network.enabled=true
# Enable the Graphite integration. Default is 'false'.
metrics.graphite.enabled=true
# The IP and port of the Graphite server on the format <hostname or IP address>:<port number>.
# The default port number for Graphite is 2003.
metrics.graphite.server=localhost:2003
# How often to send data. Default is 3 seconds.
metrics.graphite.interval=3s
# Prefix for Neo4j metrics on Graphite server.
metrics.prefix=Neo4j
----

Like you see, I just :

* enable the metrics feature and also each familly metric.
* enable the graphite integration, and configure its location, time interval and the prefix.

You don't have to change anything, just leave those lines as it.
Just notice that I have set the `metrics.prefix` to `Neo4j` you will see why on the next section.

=== Telegraf

==== Installation

There are many ways to install Telegraf on your system, and you can check directly on https://docs.influxdata.com/telegraf/v1.6/introduction/installation/#installation[the documentation].

My prefer OS is *debian*, so I will show you how to do on it :

* add the influxdb repository key
* add the repository
* perfom an update
* install the package `telegraf`

[source,bash]
----
curl -sL https://repos.influxdata.com/influxdb.key | apt-key add -
echo "deb https://repos.influxdata.com/debian jessie stable" | tee -a /etc/apt/sources.list
sudo apt-get update
apt-get install telegraf
----

==== Configuration

All *Telegraf*'s configuration is located in the file `/etc/telegraf/telegraf.conf`.

Firstly we need tell telegraf to be able to act as a graphite server :

[source,property]
----
[[inputs.socket_listener]]
  service_address = "tcp://:2003"
  separator = "."
  data_format = "graphite"
  separator = "."
  templates = [
    "Neo4j.neo4j.* ..measurement.field* host=euler,name=neo4j",
    "Neo4j.vm.* ..measurement.field* host=euler,name=neo4j"
  ]
----

I think it's easy to understand, except for the `templates` part.
In fact, in graphite all metrics follow this schema : ``

-- TODO:  --

So we need to tell *Telegraf* how to parse it to find the field measurement, the value,  and tags.

Moreover, at the end of each template you can see this `host=euler,name=neo4j`.
It's a list of static tags that will be added to each metric.
This can be really useful if you want to monitor multiple Neo4j server (like a cluster).
It will allow you to distinguish your servers on influxdb queries.

And then, we configure *Telegraf* to push the collected metrics to our centralized *influx* database.
You just have to change the `urls` property with yours (in my case `http://10.0.0.12:8086`), and optionnally the database name and the rentention policy your want.

[source,property]
----
[[outputs.influxdb]]
  ## The full HTTP or UDP URL for your InfluxDB instance.
  urls = ["http://10.0.0.12:8086"]

  ## The target database for metrics; will be created as needed.
  database = "telegraf"

  ## Name of existing retention policy to write to.  Empty string writes to
  ## the default retention policy.
  retention_policy = ""
----

NOTE: In the general section of the configuration, you can configure the batch size if you want.

== Chronograf



== Kapaictor
